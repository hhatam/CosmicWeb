{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d4c4096",
   "metadata": {},
   "source": [
    "## 0. Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9ec54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical and Scientific Computing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import math\n",
    "from numba import jit\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "\n",
    "from scipy import special\n",
    "from scipy.integrate import quad\n",
    "from scipy import integrate\n",
    "from scipy import stats\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# Plotting and Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "from matplotlib import gridspec\n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter, AutoMinorLocator)\n",
    "import matplotlib as mpl\n",
    "from matplotlib import ticker, cm\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from tabulate import tabulate\n",
    "\n",
    "import pyregion\n",
    "\n",
    "# File Handling\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "\n",
    "# Astronomical\n",
    "\n",
    "from astropy.cosmology import FlatLambdaCDM\n",
    "from astropy.cosmology import Planck15\n",
    "import astropy.units as u\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "from astroML.stats import binned_statistic_2d\n",
    "\n",
    "\n",
    "# Other\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b39197",
   "metadata": {},
   "source": [
    "## 1. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bf1a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "c0 = 3e5\n",
    "H_0 = 70\n",
    "Omega_l = 0.7\n",
    "Omega_m = 0.3\n",
    "\n",
    "lim_deltaz = 2\n",
    "\n",
    "cosmo = FlatLambdaCDM(H0 = H_0, Om0 = Omega_m)\n",
    "\n",
    "###########################################################################\n",
    "############################ LSS functions ################################\n",
    "###########################################################################\n",
    "\n",
    "def M_lim(z):\n",
    "    \"\"\"Fitting function for the mass completeness limit Weaver et. al 2022\"\"\"\n",
    "    return np.log10(-1.51e6 * (1+z) + 6.8e7 * (1+z)**2)\n",
    "\n",
    "def M_lim_ks(z):\n",
    "    \"\"\"Fitting function for mass completeness limit (on K_s) Weaver et al 2022\"\"\"\n",
    "    return np.log10(-3.55e8 * (1+z) + 2.7e8 * (1+z)**2)\n",
    "\n",
    "def slice_width(z):\n",
    "    \"\"\"Calculate the width of each redshift slice of size _physical_width_ (Mpc h^-1)\"\"\"\n",
    "    return physical_width * 100 / c0 * np.sqrt(Omega_m * (1+z)**3 + Omega_l)\n",
    "\n",
    "\n",
    "def redshift_bins(zmin, zmax):\n",
    "    \"\"\"returns the slice centers and widths, given a physical length in (Mpc h^-1) \"\"\"\n",
    "    centers = []\n",
    "    centers.append(zmin + 0.5 * slice_width(zmin))\n",
    "\n",
    "    i = 0\n",
    "    while (centers[i] + slice_width(centers[i]) < zmax ):\n",
    "        centers.append(centers[i] + slice_width(centers[i]))\n",
    "        i += 1\n",
    "\n",
    "    centers = np.array(centers)\n",
    "\n",
    "    \"redshift edges\"\n",
    "    edges = np.zeros((len(centers), 2))\n",
    "\n",
    "    for i in range(0, len(centers)):\n",
    "        edges[i, 0] = centers[i] - slice_width(centers[i]) / 2\n",
    "        edges[i, 1] = centers[i] + slice_width(centers[i]) / 2\n",
    "\n",
    "    return (centers, edges)\n",
    "\n",
    "\n",
    "def cartesian_from_polar(phi, theta):\n",
    "    \"\"\" \n",
    "    phi, theta : float or numpy.array\n",
    "        azimuthal and polar angle in radians.\n",
    "    Returns\n",
    "    -------\n",
    "    nhat : numpy.array\n",
    "        unit vector(s) in direction (phi, theta).\n",
    "    \"\"\"\n",
    "    x = np.sin(theta) * np.cos(phi)\n",
    "    y = np.sin(theta) * np.sin(phi)\n",
    "    z = np.cos(theta)\n",
    "    return np.array([x, y, z])\n",
    "\n",
    "def cos_dist(alpha, delta, alpha0, delta0):\n",
    "    \"\"\" gets all angles in [deg]\"\"\"\n",
    "    phi = alpha * np.pi / 180\n",
    "    theta = np.pi / 2 - delta * np.pi / 180\n",
    "    phi0 = alpha0 * np.pi / 180\n",
    "    theta0 = np.pi / 2 - delta0 * np.pi / 180\n",
    "    \n",
    "    x = cartesian_from_polar(phi, theta)\n",
    "    x0 = cartesian_from_polar(phi0, theta0)\n",
    "    cosdist = np.tensordot(x, x0, axes=[[0], [0]])\n",
    "    return np.clip(cosdist, 0, 1)\n",
    "\n",
    "def logsinh(x):\n",
    "    if np.any(x < 0):\n",
    "        raise ValueError(\"logsinh only valid for positive arguments\")\n",
    "    return x + np.log(1-np.exp(-2*x)) - np.log(2)\n",
    "\n",
    "def Log_K(alpha, delta, alpha0, delta0, kappa):\n",
    "    norm = -np.log(4 * np.pi / kappa) - logsinh(kappa)\n",
    "    return norm + cos_dist(alpha, delta, alpha0, delta0) * kappa\n",
    "\n",
    "def σ_k(X0, b, points):\n",
    "    kappa = 1 / (b * np.pi / 180)**2\n",
    "    X0_x = points[X0, 0]\n",
    "    X0_y = points[X0, 1]\n",
    "\n",
    "    # Use boolean mask instead of np.delete\n",
    "    mask = np.ones(len(points), dtype=bool)\n",
    "    mask[X0] = False\n",
    "    rem = points[mask]\n",
    "\n",
    "    arr = rem[:, 2] * np.exp(Log_K(rem[:, 0], rem[:, 1], X0_x, X0_y, kappa))\n",
    "    return np.sum(arr)\n",
    "\n",
    "def LCV(b, points):\n",
    "    N = len(points)\n",
    "    arr1 = [np.log(σ_k(i, b, points)) for i in range(N)]\n",
    "    return np.mean(arr1)\n",
    "\n",
    "\n",
    "def σ_k_gaussian(X0, b, points):\n",
    "    X0_x = points[X0, 0]\n",
    "    X0_y = points[X0, 1]\n",
    "    rem = np.delete(points, X0, axis = 0)\n",
    "\n",
    "    Cosdists = cos_dist(rem[:, 0], rem[:, 1], X0_x, X0_y)\n",
    "    arr = rem[:, 2] * norm.pdf(np.arccos(Cosdists[:]), loc = 0, scale = b * np.pi / 180)\n",
    "    return np.sum(arr)\n",
    "\n",
    "def σ(alpha, delta, b_i, points):\n",
    "    kappa = 1 / (b_i * np.pi / 180)**2\n",
    "    arr2 = points[:, 2] * np.exp(Log_K(points[:, 0], points[:, 1], alpha, delta, kappa))\n",
    "    return np.sum(arr2)\n",
    "\n",
    "def Adaptive_b(b, points):\n",
    "    g_i = np.array([np.log(points[i, 4] * σ(points[i, 0], points[i, 1], b, points)) for i in range(0, len(points))])\n",
    "    log_g = 1 / len(points) * np.sum(g_i)\n",
    "    b_i = np.array([(b * (points[i, 4] * σ(points[i, 0], points[i, 1], b, points) / np.exp(log_g))** -0.5) for i in tqdm(range(0, len(points)))])\n",
    "    return b_i\n",
    "\n",
    "def divider_NUV(rj):\n",
    "    return (3*rj+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebfe96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(work_path='.'):\n",
    "    '''\n",
    "    Set up all of the necessary directories\n",
    "    '''\n",
    "    for subdir in ('inputs', 'outputs', 'bin', \n",
    "                   'outputs/plots', 'outputs/weights', 'outputs/density'):\n",
    "        path = os.path.join(work_path, subdir)\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)  # Create intermediate directories automatically\n",
    "            print(f'Built directory: {os.path.abspath(path)}')  # Use absolute paths for clarity\n",
    "    \n",
    "    outputs_dir = os.path.join(work_path, 'outputs')\n",
    "    plots_dir = os.path.join(work_path, 'outputs', 'plots')  # Ensure consistent separators\n",
    "    inputs_dir = os.path.join(work_path, 'inputs')\n",
    "    weight_dir = os.path.join(work_path, 'outputs', 'weights')  # Consistent separators\n",
    "    density_dir = os.path.join(work_path, 'outputs', 'density')  # Consistent separators\n",
    "    return outputs_dir, plots_dir, inputs_dir, weight_dir, density_dir\n",
    "\n",
    "cat_dir = \"where you want to set up the catalog directories\"\n",
    "\n",
    "outputs_dir, plots_dir, inputs_dir, weights_dir, density_dir = setup(work_path=cat_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd256f9",
   "metadata": {},
   "source": [
    "## 2 Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e654ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_min, z_max = 0.4, 9.5\n",
    "\n",
    "physical_width = 35 # h^-1 Mpc\n",
    "\n",
    "slice_centers, z_edges = redshift_bins(z_min, z_max)\n",
    "\n",
    "z_width = z_edges[:, 1] - z_edges[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2d65fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = \"path to your data file\"\n",
    "\n",
    "threshold = 0.05\n",
    "\n",
    "# Load the .npy files\n",
    "weights = np.load(os.path.join(weights_dir, f'weights_unthresholded_normalized_thresh{threshold}_lengh{physical_width}.npy'))\n",
    "weights_block = np.load(os.path.join(weights_dir, f'weightsBlock_unthresholded_normalized_thresh{threshold}_lengh{physical_width}.npy'))\n",
    "W = np.load(os.path.join(weights_dir, f'weightsBlock_thresh{threshold}_normalized_lengh{physical_width}.npy'))\n",
    "normalized_delta_z_median = np.load(os.path.join(weights_dir, f'normalized_delta_z_median_thresh{threshold}_lengh{physical_width}.npy'))\n",
    "delta_z_median = np.load(os.path.join(weights_dir, f'delta_z_median_thresh{threshold}_lengh{physical_width}.npy'))\n",
    "count_in_zslice = np.load(os.path.join(weights_dir, f'count_in_zslice_thresh{threshold}_lengh{physical_width}.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee747cb3",
   "metadata": {},
   "source": [
    "## 3. b Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8fa511",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_bandwidths = np.zeros(len(slice_centers))\n",
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "for i in range(len(slice_centers)):\n",
    "    print('Progress:', i / len(slice_centers) * 100, '%')\n",
    "\n",
    "    zmin1 =  z_edges[i, 0]\n",
    "    zmax1 = z_edges[i, 1]\n",
    "\n",
    "\n",
    "    sel = (Data['zPDF'] > zmin1) & (Data['zPDF'] < zmax1)\n",
    "\n",
    "    sub_Data = Data[sel]\n",
    "\n",
    "    # calculating weights for this sample\n",
    "\n",
    "    weights1 = np.zeros(len(sub_Data))\n",
    "    delta_z_1 = sub_Data['zPDF_u68'] - sub_Data['zPDF_l68']\n",
    "    sigma_1 = delta_z_1 / 2\n",
    "    mu_1 = sub_Data['zPDF']\n",
    "    Gauss_coeff = 1 / (np.sqrt(2) * sigma_1)\n",
    "\n",
    "    weights1 = 0.5 * (special.erf(Gauss_coeff * (mu_1 - zmin1)) - special.erf(Gauss_coeff * (mu_1 - zmax1)) )\n",
    "\n",
    "    # Rotation matrix for the field\n",
    "    tan = (1.7259 - 1.9644) / (149.66 - 150.31) \n",
    "    theta = -np.arctan(tan)\n",
    "\n",
    "    x = np.cos(theta) * sub_Data['ra_detec'] + np.sin(theta) * sub_Data['dec_detec']\n",
    "    y = -np.sin(theta) * sub_Data['ra_detec'] + np.cos(theta) * sub_Data['dec_detec']\n",
    "\n",
    "    # Convert x, y, weights1 to a structured NumPy array for efficient access\n",
    "    pts = np.column_stack((x, y, weights1))\n",
    "\n",
    "    # Define grid for bandwidth optimization\n",
    "    b_grid = np.logspace(np.log10(0.005), np.log10(0.3), 100)\n",
    "    if len(pts) == 0:\n",
    "        print('No points in this slice')\n",
    "        best_bandwidths[i] = np.nan\n",
    "    else:\n",
    "        print('Number of points in this slice:', len(pts))\n",
    "\n",
    "        # Define function to maximize\n",
    "        def neg_LCV(b):\n",
    "            return -LCV(b, pts)\n",
    "\n",
    "        # Continuous optimization\n",
    "        res = minimize_scalar(\n",
    "            neg_LCV,\n",
    "            bounds=(0.001, 0.3),\n",
    "            method='bounded'\n",
    "        )\n",
    "\n",
    "        b = res.x\n",
    "        print('z_min:', zmin1, 'z_max:', zmax1)\n",
    "        print('Best global bandwidth:', b)\n",
    "\n",
    "        best_bandwidths[i] = b\n",
    "        print('_______________________________________')\n",
    "\n",
    "best_bandwidths = np.nan_to_num(best_bandwidths, nan=np.nanmean(best_bandwidths))\n",
    "np.save(os.path.join(weights_dir, f'best_bandwidths_thresh{threshold}_lengh{physical_width}.npy'), best_bandwidths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
