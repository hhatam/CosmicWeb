{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "import glob\n",
    "from scipy.interpolate import RegularGridInterpolator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Step 0: Define global parameters and functions\n",
    "# -------------------------------\n",
    "\n",
    "tan = (1.7259 - 1.9644) / (149.66 - 150.31) \n",
    "theta = -np.arctan(tan)\n",
    "\n",
    "def rotate_coordinates(ra, dec, theta):\n",
    "    x = np.cos(theta) * ra + np.sin(theta) * dec\n",
    "    y = -np.sin(theta) * ra + np.cos(theta) * dec\n",
    "    return x, y\n",
    "\n",
    "c0 = 3e5\n",
    "physical_width = 35  # in (Mpc/h)\n",
    "H_0 = 70\n",
    "Omega_m = 0.3\n",
    "Omega_l = 0.7\n",
    "\n",
    "def slice_width(z):\n",
    "    return physical_width * 100 / c0 * np.sqrt(Omega_m * (1+z)**3 + Omega_l)\n",
    "\n",
    "def redshift_bins(zmin, zmax):\n",
    "    centers = [zmin + 0.5 * slice_width(zmin)]\n",
    "    i = 0\n",
    "    while centers[i] + slice_width(centers[i]) < zmax:\n",
    "        centers.append(centers[i] + slice_width(centers[i]))\n",
    "        i += 1\n",
    "    centers = np.array(centers)\n",
    "    edges = np.zeros((len(centers), 2))\n",
    "    for i in range(len(centers)):\n",
    "        edges[i, 0] = centers[i] - slice_width(centers[i]) / 2\n",
    "        edges[i, 1] = centers[i] + slice_width(centers[i]) / 2\n",
    "    return centers, edges\n",
    "\n",
    "# -------------------------------\n",
    "# Step 1: Load Data and compute rotated positions\n",
    "# -------------------------------\n",
    "data_csv_path = \"path to your data\"\n",
    "Data = pd.read_csv(data_csv_path)\n",
    "Data['x'], Data['y'] = rotate_coordinates(Data['ra_detec'], Data['dec_detec'], theta)\n",
    "\n",
    "\n",
    "x_min = Data['x'].min()\n",
    "x_max = Data['x'].max()\n",
    "y_min = Data['y'].min()\n",
    "y_max = Data['y'].max()\n",
    "\n",
    "# -------------------------------\n",
    "# Step 2: Reconstruct the common grid\n",
    "# -------------------------------\n",
    "mesh_y = 120\n",
    "width = x_max - x_min\n",
    "height = y_max - y_min\n",
    "wh_ratio = width / height\n",
    "mesh_x = int(wh_ratio * mesh_y)\n",
    "\n",
    "gr_x = np.linspace(x_min, x_max, mesh_x)\n",
    "gr_y = np.linspace(y_min, y_max, mesh_y)\n",
    "\n",
    "# -------------------------------\n",
    "# Step 3: Get slice information and set up output matrix\n",
    "# -------------------------------\n",
    "z_min_val, z_max_val = 0.4, 9.5\n",
    "slice_centers, _ = redshift_bins(z_min_val, z_max_val)\n",
    "num_slices = len(slice_centers)\n",
    "n_galaxies = len(Data)\n",
    "\n",
    "density_excess_matrix = np.zeros((n_galaxies, num_slices))\n",
    "\n",
    "# -------------------------------\n",
    "# Step 4: Loop over slices: interpolate density excess\n",
    "# -------------------------------\n",
    "density_dir = r'~\\Results\\outputs\\density'\n",
    "\n",
    "# Build (y, x) points once â€” RegularGridInterpolator expects this order\n",
    "interp_points = Data[['y', 'x']].to_numpy()\n",
    "\n",
    "for s in range(num_slices):\n",
    "    pattern = os.path.join(density_dir, f\"output_slice_{s}_*.npz\")\n",
    "    files_found = glob.glob(pattern)\n",
    "\n",
    "    if not files_found:\n",
    "        print(f\"Warning: No file found for slice {s}\")\n",
    "        continue\n",
    "    \n",
    "    slice_file = files_found[0]\n",
    "    slice_data = np.load(slice_file)\n",
    "    density_excess_grid = slice_data['density_excess']\n",
    "\n",
    "    # Create interpolator and evaluate all galaxies at once\n",
    "    interp = RegularGridInterpolator((gr_y, gr_x), density_excess_grid, bounds_error=False, fill_value=np.nan)\n",
    "    density_excess_matrix[:, s] = interp(interp_points)\n",
    "\n",
    "    print(f\"Processed slice {s}: {os.path.basename(slice_file)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(work_path='.'):\n",
    "    '''\n",
    "    Set up all of the necessary directories\n",
    "    '''\n",
    "    for subdir in ('inputs', 'outputs', 'bin', \n",
    "                   'outputs/plots', 'outputs/weights', 'outputs/density'):\n",
    "        path = os.path.join(work_path, subdir)\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "            print(f'Built directory: {os.path.abspath(path)}') \n",
    "    \n",
    "    outputs_dir = os.path.join(work_path, 'outputs')\n",
    "    plots_dir = os.path.join(work_path, 'outputs', 'plots')\n",
    "    inputs_dir = os.path.join(work_path, 'inputs')\n",
    "    weight_dir = os.path.join(work_path, 'outputs', 'weights')\n",
    "    density_dir = os.path.join(work_path, 'outputs', 'density')\n",
    "    return outputs_dir, plots_dir, inputs_dir, weight_dir, density_dir\n",
    "\n",
    "cat_dir = \"where you want to set up the catalog directories\"\n",
    "\n",
    "outputs_dir, plots_dir, inputs_dir, weights_dir, density_dir = setup(work_path=cat_dir)\n",
    "\n",
    "\n",
    "threshold = 0.05\n",
    "\n",
    "weights = np.load(os.path.join(weights_dir, f'weights_unthresholded_normalized_thresh{threshold}_lengh{physical_width}.npy'))\n",
    "weights_block = np.load(os.path.join(weights_dir, f'weightsBlock_unthresholded_normalized_thresh{threshold}_lengh{physical_width}.npy'))\n",
    "W = np.load(os.path.join(weights_dir, f'weightsBlock_thresh{threshold}_normalized_lengh{physical_width}.npy'))\n",
    "normalized_delta_z_median = np.load(os.path.join(weights_dir, f'normalized_delta_z_median_thresh{threshold}_lengh{physical_width}.npy'))\n",
    "delta_z_median = np.load(os.path.join(weights_dir, f'delta_z_median_thresh{threshold}_lengh{physical_width}.npy'))\n",
    "count_in_zslice = np.load(os.path.join(weights_dir, f'count_in_zslice_thresh{threshold}_lengh{physical_width}.npy'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute numerator: weighted sum along slices (axis 1)\n",
    "weighted_sum = np.nansum(W * density_excess_matrix, axis=1)\n",
    "\n",
    "# Compute denominator: sum of weights per galaxy\n",
    "sum_weights = np.nansum(W, axis=1)\n",
    "\n",
    "final_density = np.where(sum_weights != 0, weighted_sum / sum_weights, 0)\n",
    "\n",
    "# Add the resulting final_density as a new column in Data\n",
    "Data['density_excess'] = final_density\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Data table with the new density_excess column\n",
    "output_csv_path = os.path.join(inputs_dir, 'COSMOSWeb_density_excess.csv')\n",
    "Data.to_csv(output_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
